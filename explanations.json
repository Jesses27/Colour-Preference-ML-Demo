{
  "ui_elements": {
    "training_phase": {
      "title": "Training Phase",
      "explanation": "This is where you teach the neural network your color preferences. Click 'I prefer this' on the color you like better. Each choice helps the network learn your taste!",
      "theory": "Supervised learning with binary classification. The network learns a mapping from RGB color space to preference probability using gradient descent optimization.",
      "math": "For each training example (x, y) where x is RGB values and y is preference (0 or 1): Loss = -[y*log(≈∑) + (1-y)*log(1-≈∑)] where ≈∑ is the network's prediction. Weights are updated using: w = w - Œ±‚àáL where Œ± is learning rate.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Supervised_learning",
          "name": "Supervised Learning"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Gradient_descent",
          "name": "Gradient Descent"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Binary_classification",
          "name": "Binary Classification"
        }
      ]
    },
    "inference_phase": {
      "title": "Prediction Mode", 
      "explanation": "Now the neural network tries to predict which color you'll prefer! The bars show the network's confidence in each prediction.",
      "theory": "Forward propagation through trained network to compute preference probabilities. The softmax function converts raw outputs to probability distributions.",
      "math": "For input x, output ≈∑ = œÉ(W‚ÇÇ¬∑ReLU(W‚ÇÅ¬∑x + b‚ÇÅ) + b‚ÇÇ) where œÉ is sigmoid function: œÉ(z) = 1/(1+e‚Åª·∂ª). Confidence = max(≈∑, 1-≈∑) * 100%",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Softmax_function",
          "name": "Softmax Function"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Sigmoid_function",
          "name": "Sigmoid Function"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Forward_propagation",
          "name": "Forward Propagation"
        }
      ]
    },
    "color_displays": {
      "title": "Color Options",
      "explanation": "These are randomly generated colors. The network learns from your preferences between these pairs.",
      "theory": "RGB color space representation with values in [0,255] range. Each color is a 3-dimensional vector representing red, green, and blue components.",
      "math": "Color vector c = [r, g, b] where r,g,b ‚àà [0,255]. Normalized input: x = [r/255, g/255, b/255] to scale values to [0,1] range.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/RGB_color_space",
          "name": "RGB Color Space"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Color_space",
          "name": "Color Space"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Color_theory",
          "name": "Color Theory"
        }
      ]
    },
    "prefer_buttons": {
      "title": "Preference Buttons",
      "explanation": "Click these to tell the network which color you prefer. This creates training data for the neural network.",
      "theory": "Binary preference labeling creates supervised learning dataset. Each choice generates a training example with RGB input and binary preference output.",
      "math": "Training pair: (x, y) where x = [r/255, g/255, b/255] and y ‚àà {0,1}. Dataset D = {(x‚ÇÅ,y‚ÇÅ), (x‚ÇÇ,y‚ÇÇ), ..., (x‚Çô,y‚Çô)}",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Labeled_data",
          "name": "Labeled Data"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Training_set",
          "name": "Training Set"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Data_labeling",
          "name": "Data Labeling"
        }
      ]
    },
    "training_stats": {
      "title": "Training Statistics",
      "explanation": "Training Examples: How many color choices you've made. Loss: How wrong the network's predictions are (lower is better). Accuracy: How often the network gets predictions right.",
      "theory": "Real-time monitoring of training progress using binary cross-entropy loss and classification accuracy metrics.",
      "math": "Loss = -(1/N)‚àë·µ¢[y·µ¢log(≈∑·µ¢) + (1-y·µ¢)log(1-≈∑·µ¢)]. Accuracy = (correct_predictions/total_predictions) √ó 100%. N = number of training examples.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Cross_entropy",
          "name": "Cross Entropy"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Accuracy_and_precision",
          "name": "Accuracy and Precision"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Evaluation_metrics",
          "name": "Evaluation Metrics"
        }
      ]
    },
    "start_inference": {
      "title": "Start Prediction Mode",
      "explanation": "Switch to prediction mode once you've trained the network with enough examples (at least 10).",
      "theory": "Minimum training examples required for meaningful generalization. Prevents overfitting and ensures network has learned sufficient patterns.",
      "math": "Minimum examples ‚â• 10 for binary classification. Rule of thumb: at least 10 examples per class for basic learning.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Generalization_error",
          "name": "Generalization Error"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Sample_size_determination",
          "name": "Sample Size Determination"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Statistical_power",
          "name": "Statistical Power"
        }
      ]
    },
    "prediction_bars": {
      "title": "Prediction Confidence",
      "explanation": "These bars show how confident the network is that you'll prefer each color. Higher percentage = more confident prediction.",
      "theory": "Probability visualization of network's confidence in binary classification. Based on sigmoid output converted to percentage.",
      "math": "Confidence = max(p, 1-p) √ó 100% where p = œÉ(z) is sigmoid output. Range: [50%, 100%] where 50% = uncertain, 100% = certain.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Confidence_interval",
          "name": "Confidence Interval"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Probability",
          "name": "Probability"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Uncertainty_quantification",
          "name": "Uncertainty Quantification"
        }
      ]
    },
    "feedback_buttons": {
      "title": "Feedback Buttons",
      "explanation": "Tell the network if its prediction was correct. If wrong, it will learn from the mistake and improve!",
      "theory": "Online learning with immediate feedback. Network updates weights based on prediction error using backpropagation.",
      "math": "Error = |prediction - actual|. Weight update: Œîw = -Œ±‚àáL where ‚àáL is gradient of loss with respect to weights.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Online_machine_learning",
          "name": "Online Machine Learning"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Backpropagation",
          "name": "Backpropagation"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Error_correction",
          "name": "Error Correction"
        }
      ]
    },
    "weight_table": {
      "title": "Neural Network Weights",
      "explanation": "This shows the strength of connections between color inputs (RGB) and neurons. Positive values (green) strengthen connections, negative (red) weaken them.",
      "theory": "Weight matrix visualization showing learned feature representations. Each weight represents connection strength between input and hidden layer neurons.",
      "math": "Weight matrix W ‚àà ‚Ñù^(3√óh) where h = hidden layer size. Element w·µ¢‚±º represents connection from input i to hidden neuron j.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Weight_(neural_networks)",
          "name": "Neural Network Weights"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Matrix_(mathematics)",
          "name": "Matrix Mathematics"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Feature_extraction",
          "name": "Feature Extraction"
        }
      ]
    },
    "weight_canvas": {
      "title": "Weight Visualization",
      "explanation": "Each square represents a weight in the neural network. Brighter squares = stronger positive weights, darker = stronger negative weights.",
      "theory": "Heatmap visualization of weight matrix. Color intensity represents weight magnitude, hue represents sign (positive/negative).",
      "math": "Normalized weight display: w_normalized = (w - min(w)) / (max(w) - min(w)). Color intensity ‚àù |w|, hue ‚àù sign(w).",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Heat_map",
          "name": "Heat Map"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Data_visualization",
          "name": "Data Visualization"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Color_mapping",
          "name": "Color Mapping"
        }
      ]
    },
    "training_insights": {
      "title": "Training Insights",
      "explanation": "Real-time analysis of how the network is learning your color preferences and what patterns it's discovering.",
      "theory": "Interpretability analysis showing learned color preferences and decision boundaries. Reveals which color components (R,G,B) are most important.",
      "math": "Feature importance = |‚àÇ≈∑/‚àÇx| where x is input feature. Gradient magnitude indicates feature sensitivity.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Interpretability",
          "name": "Interpretability"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Feature_importance",
          "name": "Feature Importance"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Explainable_AI",
          "name": "Explainable AI"
        }
      ]
    },
    "color_sensitivity": {
      "title": "Color Sensitivity Analysis",
      "explanation": "This shows which color component (Red, Green, or Blue) the network considers most important when making predictions. The dominant color has the strongest average weight connections.",
      "theory": "Feature importance analysis using weight magnitude as proxy for sensitivity. Higher average absolute weights indicate stronger influence of that color component on predictions.",
      "math": "Sensitivity = (1/n)‚àë·µ¢|w·µ¢| where w·µ¢ are weights for color component. Dominant color = argmax(sensitivity_red, sensitivity_green, sensitivity_blue).",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Feature_importance",
          "name": "Feature Importance"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Feature_selection",
          "name": "Feature Selection"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Interpretability",
          "name": "Interpretability"
        }
      ]
    },
    "weight_changes": {
      "title": "Weight Change Monitoring",
      "explanation": "This tracks how much the network's internal connections (weights) are changing during training. High activity means the network is actively learning, low activity suggests it's stabilizing.",
      "theory": "Learning dynamics analysis through weight change monitoring. Large changes indicate active learning, small changes suggest convergence or overfitting.",
      "math": "Average change = (1/n)‚àë·µ¢|Œîw·µ¢| where Œîw·µ¢ = w·µ¢_new - w·µ¢_old. Activity level: High > 0.1, Medium > 0.05, Low ‚â§ 0.05.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Convergence_(mathematics)",
          "name": "Convergence"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Learning_rate",
          "name": "Learning Rate"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Gradient_descent",
          "name": "Gradient Descent"
        }
      ]
    },
    "learning_pattern": {
      "title": "Learning Pattern Analysis",
      "explanation": "This analyzes the recent trend in loss and accuracy to understand how the network is learning. Decreasing loss and increasing accuracy indicate good learning progress.",
      "theory": "Learning curve analysis using recent training history. Monitors convergence patterns and identifies potential issues like overfitting or underfitting.",
      "math": "Loss trend = sign(L‚ÇÉ - L‚ÇÅ) where L·µ¢ are last 3 loss values. Accuracy trend = sign(A‚ÇÉ - A‚ÇÅ) where A·µ¢ are last 3 accuracy values. Positive = improving, negative = degrading.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Learning_curve",
          "name": "Learning Curve"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Convergence_analysis",
          "name": "Convergence Analysis"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Model_validation",
          "name": "Model Validation"
        }
      ]
    },
    "prediction_confidence": {
      "title": "Prediction Confidence Assessment",
      "explanation": "This estimates how confident the network is in its predictions based on training performance. Higher confidence means the network has learned reliable patterns from your preferences.",
      "theory": "Confidence estimation based on training accuracy and data sufficiency. Combines model performance with training data quantity to assess prediction reliability.",
      "math": "Confidence = f(accuracy, training_examples) where f is confidence function. High: accuracy > 0.8, Medium: accuracy > 0.6, Low: accuracy ‚â§ 0.6 or insufficient data.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Confidence_interval",
          "name": "Confidence Interval"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Uncertainty_quantification",
          "name": "Uncertainty Quantification"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Statistical_significance",
          "name": "Statistical Significance"
        }
      ]
    },
    "model_switcher": {
      "title": "Model Switcher",
      "explanation": "Switch between two different learning approaches: <strong>Neural Network</strong> (learns complex patterns through gradient descent) and <strong>Rule-Based (HSV)</strong> (uses simple color space rules). Each model has different strengths and learning characteristics.",
      "theory": "Model comparison between parametric (neural network) and non-parametric (rule-based) approaches. Neural networks learn complex, non-linear decision boundaries, while rule-based models use interpretable color space heuristics.",
      "math": "Neural network: ≈∑ = f(x;Œ∏) where Œ∏ are learned parameters. Rule-based: ≈∑ = Œ£·µ¢ w·µ¢¬∑rule·µ¢(x) where rules are predefined color heuristics.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Parametric_model",
          "name": "Parametric Model"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Rule-based_system",
          "name": "Rule-Based System"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Model_comparison",
          "name": "Model Comparison"
        }
      ]
    }
  },
  "interactions": {
    "color_preference_clicked": {
      "title": "Training the Network",
      "explanation": "You just taught the network! Your choice becomes training data. The network adjusts its weights to better predict your preferences next time.",
      "theory": "Stochastic gradient descent with single example. Network updates weights immediately after each training example to minimize prediction error.",
      "math": "For training example (x, y): w ‚Üê w - Œ±‚àáL(w;x,y) where L is binary cross-entropy loss and Œ± is learning rate (typically 0.01-0.1).",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Stochastic_gradient_descent",
          "name": "Stochastic Gradient Descent"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Online_learning",
          "name": "Online Learning"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Adaptive_learning_rate",
          "name": "Adaptive Learning Rate"
        }
      ]
    },
    "prediction_made": {
      "title": "Network Prediction",
      "explanation": "The network analyzed both colors and predicted which one you'd prefer based on your previous choices. The confidence bars show how sure it is.",
      "theory": "Forward propagation through trained network to compute preference probabilities. Network applies learned decision boundary to new color pairs.",
      "math": "For colors c‚ÇÅ, c‚ÇÇ: p‚ÇÅ = œÉ(f(c‚ÇÅ)), p‚ÇÇ = œÉ(f(c‚ÇÇ)) where f is network function. Prediction = argmax(p‚ÇÅ, p‚ÇÇ), confidence = max(p‚ÇÅ, p‚ÇÇ).",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Decision_boundary",
          "name": "Decision Boundary"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Probability_theory",
          "name": "Probability Theory"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Classification",
          "name": "Classification"
        }
      ]
    },
    "feedback_given": {
      "title": "Learning from Feedback",
      "explanation": "If the prediction was wrong, the network learns from its mistake and adjusts its weights. This is called 'supervised learning'!",
      "theory": "Error-driven learning where prediction errors guide weight updates. Network minimizes loss function through gradient descent.",
      "math": "Error = |≈∑ - y|. Weight update: Œîw = -Œ±¬∑‚àÇL/‚àÇw where L = -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)] and ‚àÇL/‚àÇw computed via backpropagation.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Supervised_learning",
          "name": "Supervised Learning"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Error-driven_learning",
          "name": "Error-Driven Learning"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Backpropagation",
          "name": "Backpropagation"
        }
      ]
    },
    "model_switched": {
      "title": "Model Changed",
      "explanation": "You switched to a different learning model! <strong>Neural Network:</strong> Uses gradient descent to learn complex patterns. <strong>Rule-Based (HSV):</strong> Uses simple color space rules. Notice how the training insights and visualizations change to reflect the different learning approach.",
      "theory": "Model selection between different learning paradigms. Neural networks: high capacity, complex patterns, gradient-based optimization. Rule-based: interpretable, simple heuristics, statistical learning.",
      "math": "Neural network complexity: O(h¬≤) parameters where h = hidden layer size. Rule-based: O(k) rules where k = number of color bins. Different optimization strategies: gradient descent vs statistical counting.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Model_selection",
          "name": "Model Selection"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Inductive_bias",
          "name": "Inductive Bias"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Computational_complexity",
          "name": "Computational Complexity"
        }
      ]
    },
    "training_complete": {
      "title": "Training Update",
      "explanation": "The network just finished learning from your choice. Notice how the weights, loss, and accuracy changed. The network is getting smarter!",
      "theory": "Convergence monitoring showing training progress. Metrics track learning dynamics and model improvement over time.",
      "math": "Loss decrease: ŒîL = L(t) - L(t-1) < 0 indicates learning. Accuracy increase: ŒîA = A(t) - A(t-1) > 0 indicates improvement.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Convergence_(mathematics)",
          "name": "Convergence"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Learning_curve",
          "name": "Learning Curve"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Convergence_analysis",
          "name": "Convergence Analysis"
        }
      ]
    },
    "inference_enabled": {
      "title": "Ready for Predictions",
      "explanation": "You've trained the network with enough examples! It's now ready to make predictions about your color preferences.",
      "theory": "Model validation threshold reached. Network has sufficient training data to generalize to new color preferences.",
      "math": "Training examples ‚â• 10 satisfies minimum data requirement. Model ready when loss < threshold and accuracy > baseline.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Model_validation",
          "name": "Model Validation"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Generalization",
          "name": "Generalization"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Statistical_significance",
          "name": "Statistical Significance"
        }
      ]
    }
  },
  "concepts": {
    "neural_network": {
      "title": "üß† Neural Network Model",
      "explanation": "A neural network is like a digital brain that learns complex patterns from examples. It has layers of 'neurons' that process information and make predictions through gradient descent optimization.",
      "theory": "Artificial neural networks are computational models inspired by biological neurons. They consist of interconnected nodes (neurons) organized in layers that process input data through weighted connections and activation functions.",
      "math": "For input x, output ≈∑ = f(x;Œ∏) where Œ∏ are learnable parameters. Each layer: h = œÉ(W¬∑x + b) where œÉ is activation function, W is weight matrix, b is bias vector.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Artificial_neural_network",
          "name": "Artificial Neural Network"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Deep_learning",
          "name": "Deep Learning"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Connectionism",
          "name": "Connectionism"
        }
      ]
    },
    "rule_based_model": {
      "title": "üìä Rule-Based (HSV) Model",
      "explanation": "A rule-based model uses simple, interpretable rules based on HSV (Hue, Saturation, Value) color space. It learns your preferences by tracking which color bins you prefer most often.",
      "theory": "Rule-based models use predefined heuristics and statistical patterns rather than learned parameters. They're more interpretable but may have limited capacity for complex patterns compared to neural networks.",
      "math": "For color c, preference ≈∑ = Œ£·µ¢ w·µ¢¬∑bin·µ¢(c) where bin·µ¢(c) indicates if color c falls in bin i, and w·µ¢ is the learned preference weight for that bin.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Rule-based_system",
          "name": "Rule-Based System"
        },
        {
          "url": "https://en.wikipedia.org/wiki/HSV_color_space",
          "name": "HSV Color Space"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Heuristic",
          "name": "Heuristic"
        }
      ]
    },
    "training": {
      "title": "How Training Works",
      "explanation": "Training means showing the network many examples and letting it adjust its internal connections (weights) to make better predictions.",
      "theory": "Training optimizes network parameters to minimize prediction error on training data. Uses gradient-based optimization algorithms to find optimal weight values.",
      "math": "Objective: min_Œ∏ L(Œ∏) = (1/N)‚àë·µ¢ L(f(x·µ¢;Œ∏), y·µ¢) where L is loss function. Update rule: Œ∏ ‚Üê Œ∏ - Œ±‚àáL(Œ∏) where Œ± is learning rate.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Optimization_(mathematics)",
          "name": "Optimization"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Gradient_descent",
          "name": "Gradient Descent"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Loss_function",
          "name": "Loss Function"
        }
      ]
    },
    "weights": {
      "title": "Understanding Weights",
      "explanation": "Weights are like the strength of connections between neurons. Positive weights strengthen connections, negative weights weaken them.",
      "theory": "Weights determine the strength and direction of information flow between neurons. They encode learned patterns and relationships in the data.",
      "math": "Weight w·µ¢‚±º connects neuron i to j. Output = œÉ(Œ£·µ¢ w·µ¢‚±º¬∑x·µ¢ + b‚±º) where œÉ is activation function. Weight magnitude |w| determines connection strength.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Weight_(neural_networks)",
          "name": "Neural Network Weights"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Connection_weight",
          "name": "Connection Weight"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Parameter_learning",
          "name": "Parameter Learning"
        }
      ]
    },
    "loss": {
      "title": "What is Loss?",
      "explanation": "Loss measures how wrong the network's predictions are. Lower loss means better predictions. The network tries to minimize loss during training.",
      "theory": "Loss function quantifies prediction error and provides optimization objective. Different loss functions are appropriate for different tasks (classification, regression).",
      "math": "Binary cross-entropy loss: L = -[y¬∑log(≈∑) + (1-y)¬∑log(1-≈∑)] where y is true label, ≈∑ is predicted probability. Range: [0,‚àû) where 0 = perfect prediction.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Loss_function",
          "name": "Loss Function"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Cross_entropy",
          "name": "Cross Entropy"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Information_theory",
          "name": "Information Theory"
        }
      ]
    },
    "accuracy": {
      "title": "What is Accuracy?",
      "explanation": "Accuracy shows what percentage of predictions the network gets right. Higher accuracy means the network is learning your preferences well.",
      "theory": "Accuracy is a classification performance metric measuring the proportion of correct predictions. It's intuitive but may not capture all aspects of model performance.",
      "math": "Accuracy = (TP + TN) / (TP + TN + FP + FN) where TP=true positives, TN=true negatives, FP=false positives, FN=false negatives. Range: [0,1].",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Accuracy_and_precision",
          "name": "Accuracy and Precision"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Confusion_matrix",
          "name": "Confusion Matrix"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Evaluation_metrics",
          "name": "Evaluation Metrics"
        }
      ]
    },
    "overfitting": {
      "title": "Overfitting",
      "explanation": "When a network memorizes training data instead of learning general patterns. This demo uses techniques like dropout to prevent overfitting.",
      "theory": "Overfitting occurs when model complexity exceeds data complexity, leading to poor generalization. Model performs well on training data but poorly on unseen data.",
      "math": "Generalization gap = E[L_test] - E[L_train] where L is loss. Overfitting when gap is large. Regularization techniques reduce model complexity.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Overfitting",
          "name": "Overfitting"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Regularization_(mathematics)",
          "name": "Regularization"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Generalization_error",
          "name": "Generalization Error"
        }
      ]
    },
    "model_comparison": {
      "title": "ü§ñ Model Comparison",
      "explanation": "<strong>Neural Network:</strong> Learns complex, non-linear patterns through gradient descent. Better for complex preferences but less interpretable. <strong>Rule-Based (HSV):</strong> Uses simple color space rules. More interpretable but may miss complex patterns. Try both to see the difference!",
      "theory": "Different learning paradigms offer different trade-offs. Neural networks excel at complex pattern recognition but are 'black boxes.' Rule-based models are interpretable but may have limited expressiveness for complex relationships.",
      "math": "Neural Network: O(h¬≤) parameters, complex decision boundaries. Rule-Based: O(k) rules, linear combinations of color bins. Complexity vs interpretability trade-off.",
      "resources": [
        {
          "url": "https://en.wikipedia.org/wiki/Model_comparison",
          "name": "Model Comparison"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Interpretability",
          "name": "Interpretability"
        },
        {
          "url": "https://en.wikipedia.org/wiki/Computational_complexity",
          "name": "Computational Complexity"
        }
      ]
    }
  }
} 